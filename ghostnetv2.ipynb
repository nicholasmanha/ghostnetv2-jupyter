{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_sigmoid(x, inplace: bool = False):\n",
    "    if inplace:\n",
    "        return x.add_(3.).clamp_(0., 6.).div_(6.)\n",
    "    else:\n",
    "        return F.relu6(x + 3.) / 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SqueezeExcite(nn.Module):\n",
    "    def __init__(self, in_chs, se_ratio=0.25, reduced_base_chs=None,\n",
    "                 act_layer=nn.ReLU, gate_fn=hard_sigmoid, divisor=4, **_):\n",
    "        super(SqueezeExcite, self).__init__()\n",
    "        self.gate_fn = gate_fn\n",
    "        reduced_chs = _make_divisible((reduced_base_chs or in_chs) * se_ratio, divisor)\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.conv_reduce = nn.Conv2d(in_chs, reduced_chs, 1, bias=True)\n",
    "        self.act1 = act_layer(inplace=True)\n",
    "        self.conv_expand = nn.Conv2d(reduced_chs, in_chs, 1, bias=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_se = self.avg_pool(x)\n",
    "        x_se = self.conv_reduce(x_se)\n",
    "        x_se = self.act1(x_se)\n",
    "        x_se = self.conv_expand(x_se)\n",
    "        x = x * self.gate_fn(x_se)\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBnAct(nn.Module):\n",
    "    def __init__(self, in_chs, out_chs, kernel_size,\n",
    "                 stride=1, act_layer=nn.ReLU):\n",
    "        super(ConvBnAct, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_chs, out_chs, kernel_size, stride, kernel_size//2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_chs)\n",
    "        self.act1 = act_layer(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveDFC(nn.Module):\n",
    "    def __init__(self, channels, redu = 4, kern_sizes = (5,9), resid = True):\n",
    "        super(AdaptiveDFC, self).__init__()\n",
    "        self.resid = resid\n",
    "        self.kern_sizes = kern_sizes\n",
    "        self.num_branch = len(kern_sizes)\n",
    "\n",
    "        # Channel Reduction\n",
    "        mid_pt = max(channels // redu, 1)\n",
    "        self.redu = nn.Conv2d(channels, mid_pt, kernel_size=1, bias=False)\n",
    "        self.batch_redu = nn.BatchNorm2d(mid_pt)\n",
    "        self.activ_redu = nn.ReLU(inplace = True)\n",
    "\n",
    "        # branches\n",
    "        self.conv_h = nn.ModuleList()\n",
    "        self.conv_w = nn.ModuleList()\n",
    "        for ker in kern_sizes:\n",
    "            k_padding = ker//2\n",
    "            # Horizontal\n",
    "            self.conv_h.append(\n",
    "                nn.Conv2d(mid_pt, mid_pt, kernel_size=(1, ker), padding =(0, k_padding), groups=mid_pt, bias=False) \n",
    "            )\n",
    "            # Vertical\n",
    "            self.conv_w.append(\n",
    "                nn.Conv2d(mid_pt, mid_pt, kernel_size=(ker, 1), padding=(k_padding, 0), groups=mid_pt, bias=False)\n",
    "            )\n",
    "    \n",
    "        # projecting to the original channels\n",
    "        self.expand = nn.Conv2d(mid_pt, channels, kernel_size=1, bias=False)\n",
    "        self.batch_expand = nn.BatchNorm2d(channels)\n",
    "    \n",
    "        # Gating mech (selecing the best path/branch)\n",
    "        hidden_gate = max(channels // 16, 1)\n",
    "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc_layer1 = nn.Linear(channels, hidden_gate, bias=False)\n",
    "        self.fc_layer2 = nn.Linear(hidden_gate, self.num_branch, bias=False)\n",
    "    \n",
    "        if resid:\n",
    "            self.alpha = nn.Parameter(torch.zeros(1))\n",
    "        else:\n",
    "            self.register_parameter(\"alpha\", None)\n",
    "\n",
    "    def forward(self, input_feat, target_feature):\n",
    "        b, c, h, w = input_feat.shape\n",
    "\n",
    "        # Reducing channels\n",
    "        u =  self.activ_redu(self.batch_redu(self.redu(input_feat)))\n",
    "\n",
    "        # calc features for each kernel branch\n",
    "        atten_maps = []\n",
    "        for cnv_h, cnv_w in zip(self.conv_h, self.conv_w):\n",
    "            attention = cnv_h(u)\n",
    "            attention = cnv_w(attention)\n",
    "            atten_maps.append(attention)\n",
    "\n",
    "        atten_stack = torch.stack(atten_maps, dim=1)\n",
    "\n",
    "        # calculating weights with softmax gate\n",
    "        gate = self.gap(input_feat).view(b,c)\n",
    "        gate = F.relu(self.fc_layer1(gate))\n",
    "        gate = self.fc_layer2(gate)\n",
    "        gate = F.softmax(gate, dim=1)\n",
    "        gate = gate.view(b, self.num_branch, 1, 1, 1)\n",
    "\n",
    "        # weighted comb\n",
    "        A_midpt = (atten_stack*gate).sum(dim=1)\n",
    "\n",
    "        # Expanding and sig activation\n",
    "        A = self.batch_expand(self.expand(A_midpt))\n",
    "        A = torch.sigmoid(A)\n",
    "\n",
    "        # interpolation\n",
    "        if A.shape[-2:] != target_feature[-2:]:\n",
    "            A = F.interpolate(A, size=target_feature.shape[-2:], mode='bilinear', align_corners=False)\n",
    "\n",
    "        #resid scaling\n",
    "        if self.resid:\n",
    "            scaling = 1.0 + self.alpha*A\n",
    "        else:\n",
    "            scaling = A\n",
    "\n",
    "        return target_feature * scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GhostModuleV2(nn.Module):\n",
    "    def __init__(self, inp, oup, kernel_size=1, ratio=2, dw_size=3, stride=1, relu=True,mode=None,args=None):\n",
    "        super(GhostModuleV2, self).__init__()\n",
    "        self.mode=mode\n",
    "        self.gate_fn=nn.Sigmoid()\n",
    "\n",
    "        if self.mode in ['original']:\n",
    "            self.oup = oup\n",
    "            init_channels = math.ceil(oup / ratio) \n",
    "            new_channels = init_channels*(ratio-1)\n",
    "            self.primary_conv = nn.Sequential(  \n",
    "                nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False),\n",
    "                nn.BatchNorm2d(init_channels),\n",
    "                nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "            )\n",
    "            self.cheap_operation = nn.Sequential(\n",
    "                nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, groups=init_channels, bias=False),\n",
    "                nn.BatchNorm2d(new_channels),\n",
    "                nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "            )\n",
    "        elif self.mode in ['attn']: \n",
    "            self.oup = oup\n",
    "            init_channels = math.ceil(oup / ratio) \n",
    "            new_channels = init_channels*(ratio-1)\n",
    "            self.primary_conv = nn.Sequential(  \n",
    "                nn.Conv2d(inp, init_channels, kernel_size, stride, kernel_size//2, bias=False),\n",
    "                nn.BatchNorm2d(init_channels),\n",
    "                nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "            )\n",
    "            self.cheap_operation = nn.Sequential(\n",
    "                nn.Conv2d(init_channels, new_channels, dw_size, 1, dw_size//2, groups=init_channels, bias=False),\n",
    "                nn.BatchNorm2d(new_channels),\n",
    "                nn.ReLU(inplace=True) if relu else nn.Sequential(),\n",
    "            ) \n",
    "            self.dfc_projection = nn.Sequential( \n",
    "                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ) \n",
    "            # replace convolution seq with adaptiveDFC implementation\n",
    "            self.short_conv = AdaptiveDFC(oup, kern_sizes=(5, 9), resid=True)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        if self.mode in ['original']:\n",
    "            x1 = self.primary_conv(x)\n",
    "            x2 = self.cheap_operation(x1)\n",
    "            out = torch.cat([x1,x2], dim=1)\n",
    "            return out[:,:self.oup,:,:]         \n",
    "        elif self.mode in ['attn']:  \n",
    "            x1 = self.primary_conv(x)\n",
    "            x2 = self.cheap_operation(x1)\n",
    "            ghost_feat = torch.cat([x1,x2], dim=1)[:,:self.oup,:,:]\n",
    "            # downsampling the input\n",
    "            if x.shape[2] > 1 and x.shape[3] > 1:\n",
    "                #res=self.short_conv(F.avg_pool2d(x,kernel_size=2,stride=2))\n",
    "                x_downspl = F.avg_pool2d(x, kernel_size=2, stride=2)\n",
    "            else:\n",
    "                #res=self.short_conv(x) \n",
    "                x_downspl = x\n",
    "  \n",
    "            # x1 = self.primary_conv(x)\n",
    "            # x2 = self.cheap_operation(x1)\n",
    "            # out = torch.cat([x1,x2], dim=1)\n",
    "            # return out[:,:self.oup,:,:]*F.interpolate(self.gate_fn(res),size=(out.shape[-2],out.shape[-1]),mode='nearest')\n",
    "\n",
    "            # projection of input\n",
    "            x_projec = self.dfc_projection(x_downspl)\n",
    "\n",
    "            # adaptice class\n",
    "            out = self.short_conv(x_projec, ghost_feat)\n",
    "\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GhostBottleneckV2(nn.Module): \n",
    "\n",
    "    def __init__(self, in_chs, mid_chs, out_chs, dw_kernel_size=3,\n",
    "                 stride=1, act_layer=nn.ReLU, se_ratio=0.,layer_id=None,args=None):\n",
    "        super(GhostBottleneckV2, self).__init__()\n",
    "        has_se = se_ratio is not None and se_ratio > 0.\n",
    "        self.stride = stride\n",
    "\n",
    "        # Point-wise expansion\n",
    "        if layer_id<=1:\n",
    "            self.ghost1 = GhostModuleV2(in_chs, mid_chs, relu=True,mode='original',args=args)\n",
    "        else:\n",
    "            self.ghost1 = GhostModuleV2(in_chs, mid_chs, relu=True,mode='attn',args=args) \n",
    "\n",
    "        # Depth-wise convolution\n",
    "        if self.stride > 1:\n",
    "            self.conv_dw = nn.Conv2d(mid_chs, mid_chs, dw_kernel_size, stride=stride,\n",
    "                             padding=(dw_kernel_size-1)//2,groups=mid_chs, bias=False)\n",
    "            self.bn_dw = nn.BatchNorm2d(mid_chs)\n",
    "\n",
    "        # Squeeze-and-excitation\n",
    "        if has_se:\n",
    "            self.se = SqueezeExcite(mid_chs, se_ratio=se_ratio)\n",
    "        else:\n",
    "            self.se = None\n",
    "            \n",
    "        self.ghost2 = GhostModuleV2(mid_chs, out_chs, relu=False,mode='original',args=args)\n",
    "        \n",
    "        # shortcut\n",
    "        if (in_chs == out_chs and self.stride == 1):\n",
    "            self.shortcut = nn.Sequential()\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_chs, in_chs, dw_kernel_size, stride=stride,\n",
    "                       padding=(dw_kernel_size-1)//2, groups=in_chs, bias=False),\n",
    "                nn.BatchNorm2d(in_chs),\n",
    "                nn.Conv2d(in_chs, out_chs, 1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_chs),\n",
    "            )\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.ghost1(x)\n",
    "        if self.stride > 1:\n",
    "            x = self.conv_dw(x)\n",
    "            x = self.bn_dw(x)\n",
    "        if self.se is not None:\n",
    "            x = self.se(x)\n",
    "        x = self.ghost2(x)\n",
    "        x += self.shortcut(residual)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GhostNetV2(nn.Module):\n",
    "    def __init__(self, cfgs, num_classes=1000, width=1.0, dropout=0.2,block=GhostBottleneckV2,args=None):\n",
    "        super(GhostNetV2, self).__init__()\n",
    "        self.cfgs = cfgs\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # building first layer\n",
    "        output_channel = _make_divisible(16 * width, 4)\n",
    "        self.conv_stem = nn.Conv2d(3, output_channel, 3, 2, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(output_channel)\n",
    "        self.act1 = nn.ReLU(inplace=True)\n",
    "        input_channel = output_channel\n",
    "\n",
    "        # building inverted residual blocks\n",
    "        stages = []\n",
    "        #block = block\n",
    "        layer_id=0\n",
    "        for cfg in self.cfgs:\n",
    "            layers = []\n",
    "            for k, exp_size, c, se_ratio, s in cfg:\n",
    "                output_channel = _make_divisible(c * width, 4)\n",
    "                hidden_channel = _make_divisible(exp_size * width, 4)\n",
    "                if block==GhostBottleneckV2:\n",
    "                    layers.append(block(input_channel, hidden_channel, output_channel, k, s,\n",
    "                                  se_ratio=se_ratio,layer_id=layer_id,args=args))\n",
    "                input_channel = output_channel\n",
    "                layer_id+=1\n",
    "            stages.append(nn.Sequential(*layers))\n",
    "\n",
    "        output_channel = _make_divisible(exp_size * width, 4)\n",
    "        stages.append(nn.Sequential(ConvBnAct(input_channel, output_channel, 1)))\n",
    "        input_channel = output_channel\n",
    "        \n",
    "        self.blocks = nn.Sequential(*stages)        \n",
    "\n",
    "        # building last several layers\n",
    "        output_channel = 1280\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.conv_head = nn.Conv2d(input_channel, output_channel, 1, 1, 0, bias=True)\n",
    "        self.act2 = nn.ReLU(inplace=True)\n",
    "        self.classifier = nn.Linear(output_channel, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stem(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.global_pool(x)\n",
    "        x = self.conv_head(x)\n",
    "        x = self.act2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        if self.dropout > 0.:\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ghostnetv2(num_classes=1000, width=1.0, dropout=0.2, args=None):\n",
    "    \"\"\"\n",
    "    Constructs a GhostNetV2 model\n",
    "    \n",
    "    Args:\n",
    "        num_classes (int): Number of output classes (default: 1000)\n",
    "        width (float): Width multiplier for channels (default: 1.0)\n",
    "        dropout (float): Dropout rate (default: 0.2)\n",
    "        args: Additional arguments\n",
    "    \n",
    "    Returns:\n",
    "        GhostNetV2 model\n",
    "    \"\"\"\n",
    "    cfgs = [\n",
    "        # k, t, c, SE, s\n",
    "        [[3,  16,  16, 0, 1]],\n",
    "        [[3,  48,  24, 0, 2]],\n",
    "        [[3,  72,  24, 0, 1]],\n",
    "        [[5,  72,  40, 0.25, 2]],\n",
    "        [[5, 120,  40, 0.25, 1]],\n",
    "        [[3, 240,  80, 0, 2]],\n",
    "        [[3, 200,  80, 0, 1],\n",
    "         [3, 184,  80, 0, 1],\n",
    "         [3, 184,  80, 0, 1],\n",
    "         [3, 480, 112, 0.25, 1],\n",
    "         [3, 672, 112, 0.25, 1]\n",
    "        ],\n",
    "        [[5, 672, 160, 0.25, 2]],\n",
    "        [[5, 960, 160, 0, 1],\n",
    "         [5, 960, 160, 0.25, 1],\n",
    "         [5, 960, 160, 0, 1],\n",
    "         [5, 960, 160, 0.25, 1]\n",
    "        ]\n",
    "    ]\n",
    "    return GhostNetV2(cfgs, num_classes=num_classes,\n",
    "                      width=width,\n",
    "                      dropout=dropout,\n",
    "                      args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully!\n",
      "Model: GhostNetV2\n"
     ]
    }
   ],
   "source": [
    "# Create model for ImageNet (1000 classes)\n",
    "model = ghostnetv2(num_classes=1000, width=1.0, dropout=0.2, args=None)\n",
    "print(\"Model created successfully!\")\n",
    "print(f\"Model: {model.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters: 8,945,182\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "print(f\"Total trainable parameters: {num_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([1, 3, 224, 224])\n",
      "Output shape: torch.Size([1, 1000])\n",
      "Output type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create a dummy input (batch_size=1, channels=3, height=224, width=224)\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output type: {output.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch input shape: torch.Size([4, 3, 224, 224])\n",
      "Batch output shape: torch.Size([4, 1000])\n"
     ]
    }
   ],
   "source": [
    "# Test with batch size of 4\n",
    "batch_input = torch.randn(4, 3, 224, 224)\n",
    "\n",
    "with torch.no_grad():\n",
    "    batch_output = model(batch_input)\n",
    "\n",
    "print(f\"Batch input shape: {batch_input.shape}\")\n",
    "print(f\"Batch output shape: {batch_output.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard model (width=1.0): 8,945,182 parameters\n",
      "Small model (width=0.5): 3,547,360 parameters\n",
      "Large model (width=1.3): 13,680,404 parameters\n"
     ]
    }
   ],
   "source": [
    "# Create a smaller model with width=0.5\n",
    "small_model = ghostnetv2(num_classes=1000, width=0.5, dropout=0.2, args=None)\n",
    "small_params = count_parameters(small_model)\n",
    "\n",
    "# Create a larger model with width=1.3\n",
    "large_model = ghostnetv2(num_classes=1000, width=1.3, dropout=0.2, args=None)\n",
    "large_params = count_parameters(large_model)\n",
    "\n",
    "print(f\"Standard model (width=1.0): {num_params:,} parameters\")\n",
    "print(f\"Small model (width=0.5): {small_params:,} parameters\")\n",
    "print(f\"Large model (width=1.3): {large_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DCT",
   "language": "python",
   "name": "dct"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
